1. 确定目标
   抓取哪个网站的哪些网页的哪部分数据
   （抓取百度百科python词条页面及其相关联页面的标题及简介）

2. 分析目标
   制定抓取这些网站数据的策略
   1. 分析抓取的这些页面的url的格式，用来限定我们要抓取的页面的范围，避免抓取不相干页面
   2. 分析要抓取的数据的格式，这里就要分析每个页面中标题和简介的标签的格式
   3. 分析页面编码，在代码的解析器处需要指定网页的编码，然后才能够进行正确的解析

3. 编写代码

4. 执行爬虫


目标： 爬取百度百科诗人信息（姓名，简介，头像网址）
入口页： http://baike.baidu.com/subview/15168/8477192.htm
URL格式： /view/12537.htm
          /subview/16967/6250840.htm
          /item/%E7%8E%8B%E7%BB%B4/37558
数据格式：
   --标题：
      <dd class="lemmaWgt-lemmaTitle-title"><h1>**</h1></dd>
   --简介：
      <div class="lemma-summary">**</div>
   --头像地址：
      <div class="summary-pic"><img src="..."></div>
页面编码： UTF-8


爬取获取地址业务流程
1. 解析网页，获取到其中所有链接接点
2. 根据链接地址结构过滤到符合条件的链接
3. 获取到链接的文字
4. 打开数据库，查询author表中有无name为链接文字的字段
5. 如果没有，跳过本链接
6. 如果有，获取到节点的地址，并存入缓存set，以待爬取

爬取数据并存储业务逻辑
1. 解析网页，根据网页结构获取到作者姓名、作者简介、作者头像图片地址
2. 打开数据库
3. 更新author表中name为作者姓名字段的简介和头像图片地址
4. 关闭数据库
